---
id: eu_mdr-数据收集报告dcr
title:
  zh: '数据收集报告(DCR)'
  en: 'Data Collection Report (DCR)'
regulation: eu_mdr
category: insights/clinical-evaluation
status: active
source_url: https://docs.team-ra.org/zh/insights/clinical-evaluation/dcr
source_url_verified: '2026-02-23'
source_format: html
translation: ai-assisted
last_verified: '2026-02-23'
contributor: RASAAS
effective_date: '2025-09-14'
---

A Data Collection Report (DCR) is a key document in the clinical evaluation process. It systematically records and summarizes the detailed procedures and direct outputs of data retrieval activities, particularly those executed according to a predefined protocol (the Literature Search Protocol (LSP) referenced in the Clinical Evaluation Plan (CEP)). The core purpose of this report is to provide a transparent, traceable, and auditable list of the original data collection results, which will then serve as the basis for subsequent data appraisal, analysis, and the compilation of the final Clinical Evaluation Report (CER).

A well-structured and comprehensive DCR typically unfolds around the following core aspects.

## **1\. Purpose, Scope, and Foundational Information of the DCR**

The introductory part of the report should first clearly articulate the **Purpose and Scope** of this DCR. This includes a clear statement that the report aims to document the collection, screening, and initial assessment process and results of relevant public data (primarily from scientific clinical literature and safety databases) for the evaluation of the safety and performance of the specific medical device(s) under evaluation (key identifying information for the device, such as its generic name, intended use, indications, target patient population, etc., should be briefly listed here). It should be explicitly stated that this data collection activity was conducted in strict accordance with the Literature Search Protocol (LSP) previously established in the Clinical Evaluation Plan (CEP), thereby establishing the DCR’s consistency with the overall clinical evaluation strategy.

## **2\. Databases Searched, Time Periods, and Any Deviations from Plan**

The DCR must meticulously document the **names of the databases actually searched and the search periods applied**. This should separately list the databases used for retrieving scientific clinical literature (e.g., PubMed, Embase) and those used for retrieving safety information (e.g., adverse events, recalls, such as FDA MAUDE, national competent authority databases like Swissmedic, BfArM, MHRA, TGA). For different types of searches (e.g., SOTA search, device-specific search), the timeframes covered (e.g., SOTA search might be limited to the last five years, while safety database searches might have no date limit to capture all relevant events) and the rationale for these timeframes (e.g., rapid technological development or the need to comprehensively capture safety events) should be clearly stated.

To ensure transparency and auditability, any **deviations from the original Literature Search Protocol (LSP)** that occurred during actual execution, along with their justifications, must be explicitly recorded in this report. If there were no deviations, this should be clearly stated.

## **3\. Confirmation of Search and Screening Criteria**

Although the detailed list of search terms and inclusion/exclusion criteria would have been established in the LSP, the DCR often reaffirms or briefly restates the **core inclusion and exclusion criteria** that were strictly applied during the actual screening process. This helps the reader understand the basis for literature selection, for example, whether only peer-reviewed published studies were included, specific languages (e.g., English), and whether in-vitro studies, animal experiments, conference abstracts, review articles, etc., were excluded.

## **4\. Brief Outline of Data Appraisal Methodology Applied**

The DCR also needs to briefly review the **data appraisal methods** employed during the data screening and initial organization phase. This might include the criteria used to assess the relevance of literature to the device under evaluation and the research questions (e.g., using a scoring system to evaluate device match, application match, patient group match, report quality), as well as criteria for an initial judgment of the scientific quality of the literature. It should be stated how these appraisal criteria were consistently applied to all identified literature and any pre-set inclusion thresholds (e.g., only articles with a relevance score above a certain value were included for further analysis).

## **5\. Presentation of Quantitative Results of the Literature Search**

This is one of the core components of the DCR, presenting the **specific execution results of the scientific literature search**. This section should present, in a clear and structured manner:

  * **Search Details for Each Database:** For each searched database, list the complete search strings actually used and the number of raw publications retrieved with that string.
  * **Summary of the Screening Process:** Aggregate the total number of publications retrieved from all databases, the number remaining after removing duplicates, and the number of publications included and excluded after title/abstract screening and full-text review. It is highly recommended to use a PRISMA flowchart or a similar diagrammatic representation to intuitively display the complete screening pathway from initial search to final inclusion of literature, including the main reasons for excluding articles at each significant stage.

## **6\. Results of Initial Appraisal of Included Literature and Data Extraction Summary**

For literature that passed the screening and was initially deemed relevant, the DCR needs to display the **results of its initial appraisal**. Listing each included publication’s basic information (e.g., citation) along with its assigned scores or ratings from the relevance assessment and preliminary scientific quality appraisal, as well as the final decision on whether it was confirmed for in-depth analysis.

The DCR should outline the **extraction of key data** from these finally included publications. This section aims to show what information relevant to device safety, performance, study design, patient characteristics, etc., has been extracted from each important publication. A structured table is also typically used here, listing key data points extracted for each publication (e.g., number of patients/subjects, clinical safety outcomes, clinical performance outcomes, study design, device model used, study location, limitations, evidence level).

## **7\. List of Excluded Articles**

To ensure the completeness and transparency of the screening process, a DCR typically includes a list of **articles that were excluded after full-text review, along with clear reasons for their exclusion**.

## **8\. Results from Safety Database Searches**

Finally, the DCR must also specifically present the **results retrieved from various safety databases**. This part should clearly list the name of each safety database searched, the search date, the specific query parameters executed (e.g., device name, report date range), and the number of relevant items found. If specific adverse event reports, recall notices, etc., were retrieved, a preliminary categorization and summary of this information might also be required.
